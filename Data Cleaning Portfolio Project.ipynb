{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00c3e74b",
   "metadata": {},
   "source": [
    "# Data Cleaning Portfolio Project\n",
    "\n",
    "## Introduction\n",
    "Data cleaning is a crucial step in data analysis and machine learning, ensuring that datasets are accurate, complete, and usable. This project focuses on cleaning a dataset by handling missing values, removing duplicates, and formatting data for better usability.\n",
    "\n",
    "## Project Overview\n",
    "This project implements a Python function that performs the following tasks:\n",
    "- **File Validation**: Ensures the dataset file exists and is in a supported format (CSV or Excel).\n",
    "- **Data Loading**: Reads data from CSV or Excel files.\n",
    "- **Data Type Standardization**: Converts columns to appropriate data types where applicable.\n",
    "- **Duplicate Handling**: Identifies and removes duplicate records, saving a copy of duplicate entries before removal.\n",
    "- **Missing Value Handling**: Fills missing numerical values with column means and removes rows with missing categorical values.\n",
    "- **Final Data Export**: Saves the cleaned dataset to an Excel file.\n",
    "\n",
    "## Steps in Data Cleaning\n",
    "\n",
    "### 1. File Validation\n",
    "- Checks if the dataset file exists.\n",
    "- Supports only CSV and Excel files; prompts an error for unsupported formats.\n",
    "\n",
    "### 2. Data Loading\n",
    "- Reads CSV files using `pandas.read_csv()`.\n",
    "- Reads Excel files using `pandas.read_excel()` with the `openpyxl` engine.\n",
    "\n",
    "### 3. Data Type Standardization\n",
    "- Converts specific columns to appropriate data types (e.g., numerical, categorical, and date values).\n",
    "- Uses `astype()` with `errors='ignore'` to prevent type conversion errors.\n",
    "\n",
    "### 4. Handling Duplicates\n",
    "- Identifies duplicate rows in the dataset.\n",
    "- Saves duplicate rows to a separate CSV file before removal.\n",
    "- Drops duplicate rows from the dataset.\n",
    "\n",
    "### 5. Handling Missing Values\n",
    "- Calculates total missing values and provides a column-wise breakdown.\n",
    "- Replaces missing numerical values with the column mean.\n",
    "- Drops rows with missing categorical values.\n",
    "\n",
    "### 6. Exporting Cleaned Data\n",
    "- Saves the cleaned dataset as an Excel file with a structured naming format.\n",
    "- Ensures data integrity and usability for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd991b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def data_cleaning(data_path):\n",
    "    \"\"\"\n",
    "    Cleans the dataset by handling missing values, removing duplicates,\n",
    "    and saving a cleaned version of the file.\n",
    "    \n",
    "    Parameters:\n",
    "        data_path (str): Path to the dataset file (CSV or Excel format).\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(data_path):\n",
    "        print(\"Error: Input a correct file path.\")\n",
    "        return None\n",
    "    \n",
    "    print(\"Dataset uploaded successfully.\")\n",
    "    \n",
    "    # Load dataset based on file type\n",
    "    if data_path.endswith(\".csv\"):\n",
    "        print(\"CSV file uploaded.\")\n",
    "        df = pd.read_csv(data_path)\n",
    "    elif data_path.endswith(\".xlsx\"):\n",
    "        print(\"Excel file uploaded.\")\n",
    "        df = pd.read_excel(data_path, engine=\"openpyxl\")\n",
    "        \n",
    "        # Convert column data types (if applicable)\n",
    "        dtype_mapping = {\n",
    "            \"Sales_ID\": str, \"Product\": str, \"Price\": float, \"Quantity\": float,\n",
    "            \"Customer_ID\": str, \"Order_Date\": str, \"City\": str, \"Sales_Rep\": str,\n",
    "            \"Discount\": float, \"Payment_Method\": str\n",
    "        }\n",
    "        for col, dtype in dtype_mapping.items():\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].astype(dtype, errors='ignore')\n",
    "        \n",
    "        df.replace(\"nan\", np.nan, inplace=True)\n",
    "    else:\n",
    "        print(\"Error: Unknown file type.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"The dataset contains {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
    "    \n",
    "    # Handling duplicate records\n",
    "    duplicate_rows = df.duplicated().sum()\n",
    "    print(f\"There are {duplicate_rows} duplicate rows in the dataset.\")\n",
    "    \n",
    "    if duplicate_rows > 0:\n",
    "        df[df.duplicated()].to_csv(f\"{data_path}_Duplicate.csv\", index=False)\n",
    "        df = df.drop_duplicates()\n",
    "        print(\"Duplicates dropped.\")\n",
    "    \n",
    "    # Handling missing values\n",
    "    total_missing_values = df.isna().sum().sum()\n",
    "    col_wise_missing = df.isna().sum()\n",
    "    \n",
    "    if total_missing_values > 0:\n",
    "        print(f\"There are {total_missing_values} missing values in the dataset.\")\n",
    "        print(col_wise_missing)\n",
    "    \n",
    "    # Fill missing values: Mean for numerical, drop rows for categorical\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype in [np.float64, np.int64]:\n",
    "            df[col].fillna(df[col].mean(), inplace=True)\n",
    "        else:\n",
    "            df.dropna(subset=[col], inplace=True)\n",
    "    \n",
    "    print(f\"Dataset cleaned! Number of rows: {df.shape[0]}, Number of columns: {df.shape[1]}\")\n",
    "    \n",
    "    # Save the cleaned data\n",
    "    output_file = f\"{data_path}_Cleaned.xlsx\"\n",
    "    df.to_excel(output_file, index=False)\n",
    "    print(f\"Cleaned data saved successfully to {output_file}\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b2c6cf",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "This project provides a structured approach to data cleaning, improving the quality and reliability of datasets for analysis and decision-making. By implementing these techniques, data analysts and data scientists can work with cleaner, more efficient datasets.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
